import { NextRequest, NextResponse } from 'next/server';
import * as sdk from 'microsoft-cognitiveservices-speech-sdk';

export async function POST(req: NextRequest) {
  try {
    const { 
      text, 
      voice = 'zh-CN-YunxiNeural', 
      style = 'chat',              
      rate = '0%',                
      pitch = '0Hz'                 
    } = await req.json();

    if (!text) return NextResponse.json({ error: 'Text required' }, { status: 400 });

    // ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ–‡æœ¬æ¸…æ´— (Regex Cleaning)
    // å»é™¤ï¼šä¸­æ–‡æ‹¬å·ï¼ˆ...ï¼‰ã€è‹±æ–‡æ‹¬å·(...)ã€æ˜Ÿå·*...*ã€æ–¹å¤´æ‹¬å·[...]ã€ä»¥åŠåˆ†éš”ç¬¦ |||
    const cleanText = text
      .replace(/ï¼ˆ.*?ï¼‰/g, '') 
      .replace(/\(.*?\)/g, '')
      .replace(/\*.*?\*/g, '')
      .replace(/\[.*?\]/g, '')
      .replace(/\|\|\|/g, 'ï¼Œ') // åˆ†éš”ç¬¦å˜é€—å·åœé¡¿
      .trim();

    // å¦‚æœæ´—å®Œæ²¡è¯äº†ï¼ˆæ¯”å¦‚åªæœ‰åŠ¨ä½œï¼‰ï¼Œç›´æ¥è¿”å›é”™è¯¯ï¼Œä¸æµªè´¹ Azure é¢åº¦
    if (cleanText.length === 0) {
       return NextResponse.json({ error: 'No speakable text' }, { status: 400 });
    }

    const speechKey = process.env.AZURE_SPEECH_KEY;
    const speechRegion = process.env.AZURE_SPEECH_REGION;

    if (!speechKey || !speechRegion) {
      return NextResponse.json({ error: 'Server config error' }, { status: 500 });
    }

    const speechConfig = sdk.SpeechConfig.fromSubscription(speechKey, speechRegion);
    speechConfig.speechSynthesisOutputFormat = sdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3;

    // æ„å»º SSML
    const ssml = `
      <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="zh-CN">
        <voice name="${voice}">
          <mstts:express-as style="${style}">
            <prosody rate="${rate}" pitch="${pitch}">
              ${cleanText}
            </prosody>
          </mstts:express-as>
        </voice>
      </speak>
    `;

    const synthesizer = new sdk.SpeechSynthesizer(speechConfig);

    return new Promise((resolve, reject) => {
      synthesizer.speakSsmlAsync(
        ssml,
        (result) => {
          if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
            const base64Audio = Buffer.from(result.audioData).toString('base64');
            synthesizer.close();
            resolve(NextResponse.json({ audio: base64Audio }));
          } else {
            synthesizer.close();
            resolve(NextResponse.json({ error: 'TTS failed' }, { status: 500 }));
          }
        },
        (error) => {
          synthesizer.close();
          resolve(NextResponse.json({ error: 'TTS error' }, { status: 500 }));
        }
      );
    });

  } catch (error) {
    return NextResponse.json({ error: 'Server error' }, { status: 500 });
  }
}