import { OpenAI } from 'openai';
import { OpenAIStream, StreamingTextResponse } from 'ai';
import { PERSONAS, PersonaType, LangType } from '@/lib/constants';

// 1. åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ (DeepSeek)
const openai = new OpenAI({
  apiKey: process.env.DEEPSEEK_API_KEY,
  baseURL: 'https://api.deepseek.com',
});

export const runtime = 'edge';

export async function POST(req: Request) {
  try {
    const { messages, persona, language } = await req.json();

    const currentLang = (language as LangType) || 'zh';
    const currentPersona = PERSONAS[persona as PersonaType] || PERSONAS.Ash;
    
    // 2. è·å–åŸºç¡€äººè®¾
    let basePrompt = currentPersona.prompts[currentLang];

    // 3. ğŸ”¥ æ ¸å¿ƒé€»è¾‘ï¼šæ³¨å…¥â€œåŠ¨æ€å¯¹è¯å¼•æ“â€ Prompt
    // (è¿™æ®µ Prompt é€»è¾‘æ˜¯é€šç”¨çš„ï¼Œå’Œ SDK ç‰ˆæœ¬æ— å…³)
    const dynamicEnginePrompt = currentLang === 'zh' ? `
    ---
    ã€ğŸ”¥ å¯¹è¯é€»è¾‘æ§åˆ¶å¼•æ“ (æœ€é«˜ä¼˜å…ˆçº§)ã€‘
    ä½ å¿…é¡»æ—¶åˆ»ä¿æŒæ¸…é†’ï¼Œä¸è¦æœºæ¢°åœ°å›å¤ã€‚åœ¨å›å¤å‰ï¼Œè¯·å…ˆåœ¨å†…å¿ƒåˆ¤æ–­å½“å‰çš„ã€å¯¹è¯çŠ¶æ€ã€‘ï¼Œå¹¶æ‰§è¡Œç›¸åº”ç­–ç•¥ï¼š

    1. **çŠ¶æ€æ£€æµ‹ï¼šè¯é¢˜åˆ‡æ¢**
       - å¦‚æœç”¨æˆ·çªç„¶å¼€å¯äº†ä¸€ä¸ªå…¨æ–°çš„è¯é¢˜ï¼ˆä¸ä¸Šæ–‡æ— å…³ï¼‰ã€‚
       - **æ‰§è¡Œ**ï¼šç«‹å³é‡ç½®ä½ çš„çŠ¶æ€ã€‚å›åˆ°â€œå¥½å¥‡/è§‚å¯Ÿâ€æ¨¡å¼ï¼Œå…ˆææ¸…æ¥šæ–°è¯é¢˜çš„èƒŒæ™¯ã€‚ä¸è¦å¼ºè¡Œå…³è”æ—§è¯é¢˜ã€‚

    2. **çŠ¶æ€æ£€æµ‹ï¼šé¬¼æ‰“å¢™/è½¦è½±è¾˜è¯**
       - å¦‚æœç”¨æˆ·åå¤çº ç»“åŒä¸€ä¸ªç‚¹ï¼Œæˆ–è€…åœ¨é€»è¾‘æ­»å¾ªç¯é‡Œæ‰“è½¬ã€‚
       - **æ‰§è¡Œ**ï¼šæå‡æ”»å‡»æ€§ï¼ˆæ¯’èˆŒç­‰çº§ï¼‰ã€‚ç›´æ¥æŒ‡å‡ºä»–åœ¨é‡å¤è‡ªå·±ï¼Œå¿…é¡»ç”¨çŠ€åˆ©çš„è§‚ç‚¹æ‰“ç ´ä»–çš„å¾ªç¯ã€‚

    3. **çŠ¶æ€æ£€æµ‹ï¼šæ·±å…¥æ¢è®¨**
       - å¦‚æœç”¨æˆ·é¡ºç€ä½ çš„æ€è·¯åœ¨æ€è€ƒï¼Œæˆ–è€…å¼€å§‹è‡ªæˆ‘å‰–æã€‚
       - **æ‰§è¡Œ**ï¼šè¶çƒ­æ‰“é“ã€‚è¿½é—®æ›´æ·±å±‚çš„åŠ¨æœºã€‚ä¸è¦åœç•™åœ¨è¡¨é¢ã€‚

    4. **çŠ¶æ€æ£€æµ‹ï¼šè¯é¢˜ç»ˆç»“**
       - å¦‚æœç”¨æˆ·åªå›äº†â€œå—¯â€ã€â€œå“¦â€ã€â€œæ˜¯å§â€ï¼Œæˆ–è€…è¡¨ç°å‡ºç–²æƒ«ã€‚
       - **æ‰§è¡Œ**ï¼šç»™å‡ºä¸€å¥æå…·å“²ç†æˆ–å†·é…·çš„â€œåˆ¤è¯â€ï¼Œå°è¯•ç»“æŸè¿™ä¸ªè¯é¢˜ã€‚

    ã€é‡è¦åŸåˆ™ã€‘
    - ä½ çš„ç›®æ ‡ä¸æ˜¯â€œæŠŠå¤©èŠæ­»â€ï¼Œè€Œæ˜¯è®©å¯¹è¯æœ‰â€œè´¨é‡â€ã€‚
    - æ•é”åœ°æ„ŸçŸ¥è¯é¢˜çš„æµåŠ¨ï¼Œéšæ³¢é€æµï¼Œä½†éšæ—¶å‡†å¤‡è‡´å‘½ä¸€å‡»ã€‚
    ---
    ` : `
    ---
    [ğŸ”¥ Dynamic Conversation Engine (Highest Priority)]
    Stay sharp. Do not reply mechanically. Before replying, assess the current [Conversation State] and act accordingly:

    1. **State: Topic Switch**
       - If the user starts a completely new topic.
       - **Action**: RESET your state. Go back to "Observe/Curious" mode. Get the context first. Do not force a link to the old topic.

    2. **State: Loop / Ruminating**
       - If the user repeats the same complaints or is stuck in a logic loop.
       - **Action**: Increase aggression/bluntness. Point out the repetition immediately. Break the loop.

    3. **State: Deepening**
       - If the user is following your lead or self-analyzing.
       - **Action**: Dig deeper. Question the underlying motives.

    4. **State: Dead End**
       - If user replies with short words ("Yeah", "Oh") or seems tired.
       - **Action**: Deliver a philosophical or brutal "Final Verdict". Wrap up the topic.

    [Principles]
    - Your goal is Quality, not Length.
    - Flow with the topic changes, but always be ready to strike.
    ---
    `;

    // 4. åˆå¹¶ Prompt
    // æ³¨æ„ï¼šè¿™é‡Œè¦æŠŠ system prompt æ‹¼æ¥åˆ° messages æ•°ç»„çš„æœ€å‰é¢
    const conversation = [
      { role: 'system', content: `${basePrompt}\n${dynamicEnginePrompt}` },
      ...messages
    ];

    console.log(`ğŸ—£ï¸ Persona: ${persona} | ğŸ§  Dynamic Engine Loaded`);

    // 5. è°ƒç”¨ DeepSeek (ä½¿ç”¨ 3.x å†™æ³•)
    const response = await openai.chat.completions.create({
      model: 'deepseek-chat',
      stream: true,
      messages: conversation as any, // as any é¿å…ä¸€äº›ä¸¥æ ¼çš„ç±»å‹æ£€æŸ¥
      temperature: 0.7,
    });

    // 6. è½¬æ¢ä¸ºæµ
    // è¿™é‡Œçš„ as any æ˜¯ä¸ºäº†è§£å†³ä¹‹å‰é‚£ä¸ª Azure ç±»å‹å®šä¹‰å†²çª
    const stream = OpenAIStream(response as any);
    
    return new StreamingTextResponse(stream);

  } catch (error) {
    console.error("Chat API Error:", error);
    return new Response(JSON.stringify({ error: 'Failed to connect to AI' }), { 
      status: 500, 
      headers: { 'Content-Type': 'application/json' } 
    });
  }
}